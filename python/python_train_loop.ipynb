{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.10.2 in c:\\python39\\lib\\site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch==1.10.2) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user torch==1.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in c:\\python39\\lib\\site-packages (0.4.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from monai) (1.22.2)\n",
      "Requirement already satisfied: torch>=1.5 in c:\\python39\\lib\\site-packages (from monai) (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch>=1.5->monai) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.metrics import compute_meandice\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    RandSpatialCropd,\n",
    "    CropForegroundd,\n",
    "    CenterSpatialCropd,\n",
    "    NormalizeIntensityd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm_gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1.WIN\\AppData\\Local\\Temp\\tmpgiwk43hx\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task02_Heart.tar: 100%|██████████| 435M/435M [05:32<00:00, 1.37MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected md5 is None, skip md5 check for file C:\\Users\\ADMINI~1.WIN\\AppData\\Local\\Temp\\tmpgiwk43hx\\Task02_Heart.tar.\n",
      "Expected md5 is None, skip md5 check for file C:\\Users\\ADMINI~1.WIN\\AppData\\Local\\Temp\\tmpgiwk43hx\\Task02_Heart.tar.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task02_Heart.tar\"\n",
    "\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task02_Heart.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task02_Heart\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (96, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True),\n",
    "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=image_size),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "     ]\n",
    " )\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True),\n",
    "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=image_size),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([96, 96, 96]), label shape: torch.Size([96, 96, 96])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 40], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 60])\n",
    "plt.show()\n",
    "print(check_data['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(score, target):\n",
    "    target = target.float()\n",
    "    smooth = 1e-5\n",
    "    intersect = torch.sum(score * target)\n",
    "    y_sum = torch.sum(target * target)\n",
    "    z_sum = torch.sum(score * score)\n",
    "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
    "    loss = 1 - loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = CacheDataset(\n",
    " #   data=train_files, transform=train_transforms,\n",
    "  #   cache_rate=1.0, num_workers=4)\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "#val_ds = CacheDataset(\n",
    " # data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = monai.networks.nets.BasicUNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.001\n",
    "max_iterations = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=base_lr, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num = 0\n",
    "alpha = 1.0\n",
    "\n",
    "lr_ = base_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 2\n",
    "val_interval = 2\n",
    "epoch_loss_values = []\n",
    "val_epoch_loss_values = []\n",
    "dice_metric_values = []\n",
    "time_list_epoch = []\n",
    "time_list_batch = []\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=2)\n",
    "post_label = AsDiscrete(to_onehot=True, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 5\n",
      "step 6\n",
      "step 7\n",
      "step 8\n",
      "step 9\n",
      "step 10\n",
      "step 11\n",
      "epoch 2\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 5\n",
      "step 6\n",
      "step 7\n",
      "step 8\n",
      "step 9\n",
      "step 10\n",
      "step 11\n",
      "val_step 1\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(max_epochs):\n",
    "    time_list_epoch.append(time.time())\n",
    "    print(f\"epoch {epoch_num + 1}\")\n",
    "    net.train()\n",
    "    step = 0\n",
    "    for i_batch, sampled_batch in enumerate(train_loader):\n",
    "         time_list_batch.append(time.time())\n",
    "        step +=1\n",
    "        print(f\"step {step}\")\n",
    "        volume_batch, label_batch = sampled_batch['image'].cuda(), sampled_batch['label'].cuda()\n",
    "        outputs = net(volume_batch)\n",
    "        outputs, label_batch = outputs.type(torch.Tensor), label_batch.type(torch.Tensor)\n",
    "\n",
    "        outputs_soft = F.softmax(outputs, dim=1)\n",
    "        # compute distance maps and hd loss\n",
    "\n",
    "\n",
    "        loss = dice_loss(outputs_soft[:, 1, :, :, :], label_batch == 1)\n",
    "        # y_pred = post_pred(outputs)\n",
    "        # y = post_label(label_batch)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch_num + 1) % val_interval == 0:\n",
    "        new_loss = 0\n",
    "        net.eval()\n",
    "        val_step = 0\n",
    "        with torch.no_grad():\n",
    "            val_step +=1\n",
    "            print(f\"val_step {val_step}\")\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].cuda(),\n",
    "                    val_data[\"label\"].cuda()\n",
    "                )\n",
    "                roi_size = (96,96,96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_inputs, roi_size, sw_batch_size, net)\n",
    "                val_outputs, val_labels = val_outputs.type(torch.Tensor), val_labels.type(torch.Tensor)\n",
    "                outputs_soft = F.softmax(val_outputs, dim=1)\n",
    "                val_loss= dice_loss(outputs_soft[:, 1, :, :, :], val_labels == 1)\n",
    "\n",
    "                # val_outputs = post_pred(val_outputs)\n",
    "                # val_labels = post_label(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(time_list_epoch)\n",
    "delta_time_epoch = np.diff(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(time_list_batch)\n",
    "delta_time_step = np.diff(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_step_time = np.mean(delta_time_step)\n",
    "avg_step_time # should be about ~2 seconds per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_epoch_time = np.mean(delta_time_epoch)\n",
    "avg_epoch_time # should be about ~20 seconds per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_epoch_time"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
